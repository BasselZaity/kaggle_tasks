{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINSET digin recognizer using MLP\n",
    "* generalization score (on kaggle)  0.977\n",
    "* training accuracy: 0.9946\n",
    "* validation accuracy: 0.9802\n",
    "\n",
    "## Model 2.1\n",
    "### Structure\n",
    "\n",
    "Use 200 neurons in hidden layers instead of 25,12 in model2 and add droup out with probability of 0.8\n",
    "\n",
    "- Input layer 784 elements\n",
    "- Hidden layer 1, 200 neurons, relu activation, dropout keep_prob=0.8\n",
    "- Hidden layer 2, 200 neurons, relu activation, dropout keep_prob=0.8\n",
    "- Output layer 10 neurons, sigmoid activation\n",
    "\n",
    "\n",
    "- Number of iterations 50\n",
    "- Loss function: categorical_crossentropy\n",
    "- Adam optimization algoithm for backpropogation\n",
    "    - learning rate 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zein/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helpers\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('./data/train.csv')\n",
    "test=pd.read_csv('./data/test.csv')\n",
    "\n",
    "trainLabels=train.label\n",
    "train.drop(\"label\",axis=1,inplace=True)\n",
    "\n",
    "train=train/256.0\n",
    "test=test/256.0\n",
    "Xtrain=train.as_matrix()\n",
    "Xtest=test.as_matrix()\n",
    "\n",
    "print( Xtrain.shape, trainLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zein/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xval, trainLabels, valLabels = train_test_split( Xtrain, trainLabels, test_size=0.1\n",
    "                                                        ,shuffle=True ,stratify=trainLabels)\n",
    "ytrain=convert_to_one_hot(trainLabels,10).T\n",
    "yval=convert_to_one_hot(valLabels,10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([413., 468., 418., 435., 407., 380., 414., 440., 406., 419.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAGABJREFUeJzt3X+w3XWd3/Hny/BDV5SfKSMBNxnN1uJODTZFXPrDwi4EcA3OqItdNWXYxm2xYtd2F5zp4qJ0dcYV147aomSFFUUG3RoRxVShO04rEASRgIzZgJIYIRpA/IUbfPeP87n0eL0399ybc889N9/nY+ZOzvfz/Z7v5/O9+dzzOt+fn1QVkqTuedpCN0CStDAMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDYD+XZEmSHyV57kK3Rd2WZHmSSnJAm/58knWDLDuHut6W5CP70t4uMADGTPuwnvj5RZKf9k3//mzXV1VPVtUhVfWd+WivuiXJF5JcMkX52iTfm80HdlWdUVVXDqFNL0uyfdK6/2tV/cG+rnt/ZwCMmfZhfUhVHQJ8B/jdvrKrJy8/129I0hxdCbwuSSaVvx64uqr2LECbNEcGwCKT5J1JPpnkE0kep/fH+NIkX03yaJKdSd6f5MC2/AFtV3p5m/5Ym//5JI8n+b9JVizgJmlx+Z/AkcA/nyhIcjjwcuCqJGcluSPJD5M8mOTt060oyc1J/qC9XpLkPUm+n2QbcNakZc9Ncm/rs9uSvLGVPxP4PHBM357yMUnenuRjfe9/RZIt7W/k5iT/qG/eA0n+U5K7kjzW/r6ePoxf1rgzABanVwIfBw4FPgnsAS4AjgJOBtYAb9zL+/818F+AI+jtZbxjPhur/UdV/RS4FnhDX/FrgG9W1deBH7d5h9H7EP93Sc4eYNX/ll6InACsBl41af7Dbf6zgXOBy5K8uKp+DJwBfLdvT/m7/W9M8hvAJ4C3AEuBG4DPJjlo0jasAVYA/xj4NwO0edEzABanr1TVZ6vqF1X106q6rapuqao9VbUNuBz4l3t5/3VVtbmq/h64Glg1klZrf3El8Kq+b8lvaGVU1c1V9Y3WN++i98G7t7444TXA+6rqwaraDfx5/8yq+lxV/V31/G/gi/Tthczg94DPVdWm1uffAzwD+K2+Zd5fVd9tdX+WjvxNGACL04P9E0lekORz7STcD4FL6O0NTOd7fa9/AhwyD23UfqqqvgJ8Hzg7yfOAE+ntkZLkJUluSrIryWPAH7L3vjjhGH65X3+7f2aSM9phzt1JHgXOHHC9E+t+an1V9YtW17K+ZTr5N2EALE6TH+H6P4C7gedX1bOBPwUmn6SThukqet/8XwfcWFUPtfKPAxuB46rqUOC/M1hf3Akc1zf91GXLSQ4GPkXvm/vRVXUYvcM4E+ud6ZHG3wV+vW99aXXtGKBd+zUDYP/wLOAx4Mft5Nbejv9Lw3AV8Nv0jt33X8r5LGB3Vf0syYn0zjcN4lrgzUmObSeVL+ybdxBwMLAL2JPkDOC0vvkPAUcmOXQv6z4ryant4oi3Ak8A/2fAtu23DID9w1uBdcDj9PYGPrmwzdH+rqoeoPcB+kx63/gn/HvgknaF2p/S+/AdxIeBG4GvA18DPt1X1+PAm9u6HqEXKhv75n+T3rmGbe0qn2MmtfU+ensq/43eoavfpXd59c8HbNt+Kw4II0nd5B6AJHWUASBJHWUASFJHGQCS1FFj/SCxo446qpYvX77QzdB+7Pbbb/9+VS0ddb32bc2nQfv1WAfA8uXL2bx580I3Q/uxJN+eeanhs29rPg3arz0EJEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR011ncCz4flF35uTu974F1nDbkl0nDZtzVb7gFIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEDB0CSJUnuSHJ9m16R5JYkW5N8MslBrfzgNr21zV/et46LWvl9SU4f9sZIkgY3mz2AC4B7+6bfDVxWVc8HHgHOa+XnAY+08svaciQ5HjgHeCGwBvhgkiX71nxJ0lwNFABJjgXOAj7SpgOcAlzXFrkSOLu9XtumafNPbcuvBa6pqieq6n5gK3DiMDZCkjR7g+4BvA/4Y+AXbfpI4NGq2tOmtwPL2utlwIMAbf5jbfmnyqd4z1OSrE+yOcnmXbt2zWJTJEmzMWMAJHk58HBV3T6C9lBVl1fV6qpavXTpjIPaS5LmaJBnAZ0MvCLJmcDTgWcDfwkcluSA9i3/WGBHW34HcBywPckBwKHAD/rKJ/S/R4uQz57R/qorfXvGPYCquqiqjq2q5fRO4n65qn4fuAl4VVtsHfCZ9npjm6bN/3JVVSs/p10ltAJYCdw6tC2RJM3KvjwN9E+Aa5K8E7gDuKKVXwH8dZKtwG56oUFVbUlyLXAPsAc4v6qe3If6F4WufJNQt9iv9w+zCoCquhm4ub3exhRX8VTVz4BXT/P+S4FLZ9tISdLweSewJHWUASBJHWUASFJHGQCS1FEGgCR1VOcGhZekcbKQl9QaAAOa63+Shsdrz+eHfbu7PAQkSR21aPcA/NYyPP4ux4v/H8Pj73Lv3AOQpI4yACSpoxbtIaD93f58wnOx7Ja3IUs3Azuq6uXtKbbX0Bvg6Hbg9VX18yQHA1cB/4Teo89/r6oeWKBmj7X9uV/D4unbE9wDkKa3T+NgS+POAJCmMKRxsKWxZgBIUxvGONi/xPGuNW4MAGmS+RoH2/GuNW4GGRT+6UluTfL1JFuS/Fkr/2iS+5Pc2X5WtfIkeX+SrUnuSvLivnWtS/Kt9rNuujqlBTYxDvYD9E76nkLfONhtmanGwWbSONjSWBtkD+AJ4JSqehGwCliT5KQ27z9X1ar2c2crO4PeeL8rgfXAhwCSHAFcDLyE3khiFyc5fHibIg3HEMfBlsbaIIPCV1X9qE0e2H721rnXAle1932V3rem5wCnA5uqandVPQJsAtbsW/OlkfoT4I/aeNdH8svjYB/Zyv8IuHCB2ifNykDnAJIsSXIn8DC9D/Fb2qxL22Gey9q10NB3QqyZOFk2XfnkujxRprFRVTdX1cvb621VdWJVPb+qXl1VT7Tyn7Xp57f52xa21dJgBgqAqnqyqlbRO+55YpLfBC4CXgD8U+AIet+O9pknyiRpNGZ1FVBVPUrvOOiaqtrZDvM8AfwVveP60HdCrJk4WTZduSRpAQxyFdDSJIe1188Afgf4ZjuuP3GDzNnA3e0tG4E3tKuBTgIeq6qdwI3AaUkObyd/T2tlkqQFMMizgJ4DXNmei/I04Nqquj7Jl5MsBQLcCfxhW/4G4ExgK/AT4FyAqtqd5B3AbW25S6pq9/A2RbD4nkUiDcJ+PT9mDICqugs4YYryU6ZZvoDzp5m3AdgwyzZKkuaBdwJLUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHXUICOCPT3JrUm+nmRLkj9r5SuS3JJka5JPJjmolR/cpre2+cv71nVRK78vyenztVGSpJkNsgfwBHBKVb0IWAWsaUM9vhu4rKqeDzwCnNeWPw94pJVf1pYjyfHAOcALgTXAB9soY5KkBTBjALSB33/UJg9sPwWcAlzXyq+kNy4wwNo2TZt/ahs3eC1wTVU9UVX30xsycmIgeUnSiA10DiDJkiR3Ag8Dm4C/Ax6tqj1tke3AsvZ6GfAgQJv/GHBkf/kU7+mva32SzUk279q1a/ZbJEkayEABUFVPVtUq4Fh639pfMF8NqqrLq2p1Va1eunTpfFUjSZ03q6uAqupR4CbgpcBhSSYGlT8W2NFe7wCOA2jzDwV+0F8+xXskSSM2yFVAS5Mc1l4/A/gd4F56QfCqttg64DPt9cY2TZv/5aqqVn5Ou0poBbASuHVYGyJJmp0DZl6E5wBXtit2ngZcW1XXJ7kHuCbJO4E7gCva8lcAf51kK7Cb3pU/VNWWJNcC9wB7gPOr6snhbo4kaVAzBkBV3QWcMEX5Nqa4iqeqfga8epp1XQpcOvtmSpKGzTuBJamjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CaZJiPQJfGmQEg/aqhPAJdGncGgDTJEB+BLo01A0CawpAegT55nT7qXGPFAJCmMB+PQPdR5xo3BoC0F/v4CHRprBkA0iRDfAS6NNYGeRy01DVDeQS6NO4MAGmSYT4CXRpnHgKSpI4aZEjI45LclOSedlfkBa387Ul2JLmz/ZzZ956L2l2R9yU5va98TSvbmuTC+dkkSdIgBjkEtAd4a1V9LcmzgNuTbGrzLquq9/QvnOR4esdAXwgcA/yvJL/RZn+A3gm17cBtSTZW1T3D2BBJ0uwMMiTkTmBne/14knv5/zfATGUtcE1VPQHc306MTRw33dqOo5LkmrasASBJC2BW5wDaQ65OAG5pRW9KcleSDUkOb2VP3RXZTNwxOV355Dq8W1KSRmDgAEhyCPAp4C1V9UPgQ8Dz6D0sayfwF8NokHdLStJoDHQZaJID6X34X11Vnwaoqof65n8YuL5NPnVXZNN/x+R05ZKkERvkKqDQu9Hl3qp6b1/5c/oWeyVwd3u9ETinPSN9BbASuBW4DVjZnql+EL0TxRuHsxmSpNkaZA/gZOD1wDfa0xEB3ga8Nskqeo/JfQB4I0BVbUlyLb2Tu3uA86vqSYAkbwJuBJYAG6pqyxC3RZI0C4NcBfQVYKpnm9+wl/dcClw6RfkNe3ufJGl0vBNYkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjBhkR7LgkNyW5J8mWJBe08iOSbEryrfbv4a08Sd6fZGsbMP7Ffeta15b/VpJ187dZkqSZDLIHsAd4a1UdD5wEnJ/keOBC4EtVtRL4UpsGOIPeMJArgfX0Bo8nyRHAxcBLgBOBiydCQ5I0ejMGQFXtrKqvtdePA/cCy4C1wJVtsSuBs9vrtcBV1fNV4LA2fvDpwKaq2l1VjwCbgDVD3RpJ0sBmdQ4gyXLgBOAW4Oiq2tlmfQ84ur1eBjzY97btrWy6cknSAhg4AJIcAnwKeEtV/bB/XlUVvcHh91mS9Uk2J9m8a9euYaxSkjSFgQIgyYH0PvyvrqpPt+KH2qEd2r8Pt/IdwHF9bz+2lU1X/kuq6vKqWl1Vq5cuXTqbbZEkzcIgVwEFuAK4t6re2zdrIzBxJc864DN95W9oVwOdBDzWDhXdCJyW5PB28ve0ViZJWgAHDLDMycDrgW8kubOVvQ14F3BtkvOAbwOvafNuAM4EtgI/Ac4FqKrdSd4B3NaWu6Sqdg9lKyRJszZjAFTVV4BMM/vUKZYv4Pxp1rUB2DCbBkqS5od3AktSRxkA0iTDvPtdGmcGgPSrhnL3uzTuDABpkiHe/S6NNQNA2ot9vPt98rq8yVFjxQCQpjHsu9+9yVHjxgCQpjCku9+lsWYASJMM8e53aawNciew1DVDuftdGncGgDTJMO9+l8aZh4AkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6qhBhoTckOThJHf3lb09yY4kd7afM/vmXdQei3tfktP7yte0sq1JLpxcjyRptAbZA/gosGaK8suqalX7uQGgPTL3HOCF7T0fTLIkyRLgA/Qem3s88Nq2rCRpgQwyJOTfticiDmItcE1VPQHcn2QrcGKbt7WqtgEkuaYte8+sWyxJGop9OQfwpjb60YaJkZGY/rG4Az0uF3xkriSNylwD4EPA84BVwE7gL4bVIB+ZK0mjMadnAVXVQxOvk3wYuL5N7u2xuD4uV5LGyJz2ACYNd/dKYOIKoY3AOUkOTrKC3hiptwK3ASuTrEhyEL0TxRvn3mxJ0r6acQ8gySeAlwFHJdkOXAy8LMkqeiMiPQC8EaCqtiS5lt7J3T3A+VX1ZFvPm4AbgSXAhqraMvStkSQNbJCrgF47RfEVe1n+UuDSKcpvoPfcdEnSGPBOYEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjZgyAJBuSPJzk7r6yI5JsSvKt9u/hrTxJ3p9ka5K7kry47z3r2vLfSrJufjZHkjSoQfYAPgqsmVR2IfClqloJfKlNA5xBbxzglcB64EPQCwx6Q0m+BDgRuHgiNCRJC2PGAKiqvwV2TypeC1zZXl8JnN1XflX1fBU4rA0gfzqwqap2V9UjwCZ+NVQkSSM013MAR1fVzvb6e8DR7fUy4MG+5ba3sunKf0WS9Uk2J9m8a9euOTZPkjSTfT4JXFUF1BDaMrG+y6tqdVWtXrp06bBWKw1sWOe9pHE31wB4qB3aof37cCvfARzXt9yxrWy6cmkcfZR9PO8lLQZzDYCNwMSVPOuAz/SVv6F9KzoJeKwdKroROC3J4e2b02mtTBo7QzrvJY29A2ZaIMkngJcBRyXZTu9qnncB1yY5D/g28Jq2+A3AmcBW4CfAuQBVtTvJO4Db2nKXVNXkPzBpnM32vNdOpDE3YwBU1WunmXXqFMsWcP4069kAbJhV66QxVFWVZNbnvZKsp3eYiOc+97lDb5c0W94JLA1mtue9foUXOGjcGADSYGZ73ksaezMeApK6ZhjnvaTFwACQJhnWeS9p3HkISJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmj9ikAkjyQ5BtJ7kyyuZU5dqokLQLD2AP4V1W1qqpWt2nHTpWkRWA+DgE5dqokLQL7GgAFfDHJ7W24O5j92Km/JMn6JJuTbN61a9c+Nk+SNJ19HQ/gn1XVjiT/ANiU5Jv9M+cydmpVXQ5cDrB69epZj7sqSRrMPu0BVNWO9u/DwN8AJzKEsVMlSfNvzgGQ5JlJnjXxGjgNuBvHTpWkRWFfDgEdDfxNkon1fLyqvpDkNhw7VZLG3pwDoKq2AS+aovwHOHaqJI097wSWpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOmrkAZBkTZL7kmxNcuGo65fmg/1ai9FIAyDJEuADwBnA8cBrkxw/yjZIw2a/1mI16j2AE4GtVbWtqn4OXAOsHXEbpGGzX2tR2pdB4ediGfBg3/R24CX9CyRZD6xvkz9Kct806zoK+P7QWzgY615E9ebde53963Ndb58Z+zXYt8e03kVb9zD69agDYEZVdTlw+UzLJdlcVatH0CTrXuC6F3Kbh8m+PX71drluGP0hoB3AcX3Tx7YyaTGzX2tRGnUA3AasTLIiyUHAOcDGEbdBGjb7tRalkR4Cqqo9Sd4E3AgsATZU1ZY5rm7GXel5ZN3dqHcgQ+7X4P+xdY9Iqmoh65ckLRDvBJakjjIAJKmjFmUALNRt90mOS3JTknuSbElywajqbvUvSXJHkutHXO9hSa5L8s0k9yZ56Qjr/o/td313kk8kefqo6h61rvbr1oZO9e1x6deLLgAW+Lb7PcBbq+p44CTg/BHf8n8BcO8I65vwl8AXquoFwItG1YYky4A3A6ur6jfpnWA9ZxR1j1rH+zV0qG+PU79edAHAAt52X1U7q+pr7fXj9DrLslHUneRY4CzgI6Oor6/eQ4F/AVwBUFU/r6pHR9iEA4BnJDkA+DXguyOse5Q62a+hs317LPr1YgyAqW67H1lnnZBkOXACcMuIqnwf8MfAL0ZU34QVwC7gr9ou+keSPHMUFVfVDuA9wHeAncBjVfXFUdS9ALrar6FjfXuc+vViDIAFl+QQ4FPAW6rqhyOo7+XAw1V1+3zXNYUDgBcDH6qqE4AfAyM5Pp3kcHrfglcAxwDPTPK6UdTdRaPu163OzvXtcerXizEAFvS2+yQH0vsjubqqPj2iak8GXpHkAXqHBk5J8rER1b0d2F5VE98Ir6P3RzMKvw3cX1W7qurvgU8DvzWiuketi/0autm3x6ZfL8YAWLDb7pOE3vHCe6vqvaOoE6CqLqqqY6tqOb3t/XJVjeQbQ1V9D3gwyT9sRacC94yibnq7yCcl+bX2uz+VhTlROAqd69fQ2b49Nv167J4GOpN5uO1+Nk4GXg98I8mdrextVXXDiOpfKP8BuLp9MG0Dzh1FpVV1S5LrgK/Ru1LlDsb8sRBzZb9eMCPv2+PUr30UhCR11GI8BCRJGgIDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSO+n8QYrgiOoe5GgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure of train_test_split work\n",
    "plt.figure(\"train/validation labels distribution\")\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Train\")\n",
    "plt.hist(trainLabels)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Validation\")\n",
    "plt.hist(valLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "import keras.layers as ll\n",
    "\n",
    "model = Sequential(name=\"mlp\")\n",
    "\n",
    "model.add(ll.InputLayer([28*28]))\n",
    "\n",
    "\n",
    "# network body\n",
    "model.add(ll.Dense(200))\n",
    "model.add(ll.Activation('relu'))\n",
    "model.add(ll.Dropout(0.2))\n",
    "\n",
    "model.add(ll.Dense(200))\n",
    "model.add(ll.Activation('relu'))\n",
    "model.add(ll.Dropout(0.2))\n",
    "\n",
    "# output layer: 10 neurons for each class with softmax\n",
    "model.add(ll.Dense(10, activation='softmax'))\n",
    "\n",
    "# categorical_crossentropy is your good old crossentropy\n",
    "# but applied for one-hot-encoded vectors\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 11s 278us/step - loss: 0.3159 - acc: 0.9027 - val_loss: 0.1390 - val_acc: 0.9588\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 9s 227us/step - loss: 0.1451 - acc: 0.9555 - val_loss: 0.1163 - val_acc: 0.9662\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 8s 217us/step - loss: 0.1085 - acc: 0.9657 - val_loss: 0.0969 - val_acc: 0.9719\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 8s 204us/step - loss: 0.0871 - acc: 0.9719 - val_loss: 0.0989 - val_acc: 0.9695\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 7s 190us/step - loss: 0.0736 - acc: 0.9763 - val_loss: 0.0929 - val_acc: 0.9726\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 8s 208us/step - loss: 0.0656 - acc: 0.9781 - val_loss: 0.0920 - val_acc: 0.9717\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.0570 - acc: 0.9815 - val_loss: 0.0792 - val_acc: 0.9767\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 9s 231us/step - loss: 0.0509 - acc: 0.9833 - val_loss: 0.0847 - val_acc: 0.9762\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 9s 230us/step - loss: 0.0493 - acc: 0.9843 - val_loss: 0.0825 - val_acc: 0.9802\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 10s 268us/step - loss: 0.0442 - acc: 0.9859 - val_loss: 0.0910 - val_acc: 0.9767\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 9s 228us/step - loss: 0.0420 - acc: 0.9861 - val_loss: 0.0934 - val_acc: 0.9745\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 8s 225us/step - loss: 0.0423 - acc: 0.9864 - val_loss: 0.0821 - val_acc: 0.9793\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 7s 195us/step - loss: 0.0349 - acc: 0.9882 - val_loss: 0.1024 - val_acc: 0.9757\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 11s 304us/step - loss: 0.0335 - acc: 0.9889 - val_loss: 0.0917 - val_acc: 0.9781\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 12s 309us/step - loss: 0.0373 - acc: 0.9875 - val_loss: 0.0831 - val_acc: 0.9802\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 10s 260us/step - loss: 0.0310 - acc: 0.9899 - val_loss: 0.0824 - val_acc: 0.9812\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 11s 286us/step - loss: 0.0327 - acc: 0.9893 - val_loss: 0.0972 - val_acc: 0.9783\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 12s 328us/step - loss: 0.0310 - acc: 0.9897 - val_loss: 0.0812 - val_acc: 0.9793\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 12s 312us/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0900 - val_acc: 0.9781\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 9s 249us/step - loss: 0.0275 - acc: 0.9912 - val_loss: 0.0960 - val_acc: 0.9776\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 8s 205us/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.0867 - val_acc: 0.9800\n",
      "Epoch 22/50\n",
      "37800/37800 [==============================] - 8s 199us/step - loss: 0.0249 - acc: 0.9919 - val_loss: 0.1123 - val_acc: 0.9755\n",
      "Epoch 23/50\n",
      "37800/37800 [==============================] - 11s 285us/step - loss: 0.0261 - acc: 0.9918 - val_loss: 0.1034 - val_acc: 0.9788\n",
      "Epoch 24/50\n",
      "37800/37800 [==============================] - 15s 402us/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.0945 - val_acc: 0.9779\n",
      "Epoch 25/50\n",
      "37800/37800 [==============================] - 8s 211us/step - loss: 0.0232 - acc: 0.9922 - val_loss: 0.1094 - val_acc: 0.9769\n",
      "Epoch 26/50\n",
      "37800/37800 [==============================] - 7s 198us/step - loss: 0.0243 - acc: 0.9925 - val_loss: 0.0975 - val_acc: 0.9776\n",
      "Epoch 27/50\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.0249 - acc: 0.9926 - val_loss: 0.1054 - val_acc: 0.9769\n",
      "Epoch 28/50\n",
      "37800/37800 [==============================] - 12s 309us/step - loss: 0.0225 - acc: 0.9930 - val_loss: 0.1132 - val_acc: 0.9767\n",
      "Epoch 29/50\n",
      "37800/37800 [==============================] - 8s 216us/step - loss: 0.0221 - acc: 0.9933 - val_loss: 0.0899 - val_acc: 0.9802\n",
      "Epoch 30/50\n",
      "37800/37800 [==============================] - 7s 197us/step - loss: 0.0241 - acc: 0.9928 - val_loss: 0.1019 - val_acc: 0.9798\n",
      "Epoch 31/50\n",
      "37800/37800 [==============================] - 9s 226us/step - loss: 0.0232 - acc: 0.9931 - val_loss: 0.1088 - val_acc: 0.9783\n",
      "Epoch 32/50\n",
      "37800/37800 [==============================] - 11s 281us/step - loss: 0.0239 - acc: 0.9926 - val_loss: 0.1001 - val_acc: 0.9805\n",
      "Epoch 33/50\n",
      "37800/37800 [==============================] - 10s 272us/step - loss: 0.0200 - acc: 0.9935 - val_loss: 0.0992 - val_acc: 0.9802\n",
      "Epoch 34/50\n",
      "37800/37800 [==============================] - 10s 264us/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.1125 - val_acc: 0.9776\n",
      "Epoch 35/50\n",
      "37800/37800 [==============================] - 12s 331us/step - loss: 0.0218 - acc: 0.9934 - val_loss: 0.1089 - val_acc: 0.9812\n",
      "Epoch 36/50\n",
      "37800/37800 [==============================] - 10s 255us/step - loss: 0.0241 - acc: 0.9932 - val_loss: 0.1040 - val_acc: 0.9800\n",
      "Epoch 37/50\n",
      "37800/37800 [==============================] - 10s 260us/step - loss: 0.0203 - acc: 0.9944 - val_loss: 0.1103 - val_acc: 0.9800\n",
      "Epoch 38/50\n",
      "37800/37800 [==============================] - 12s 322us/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.1034 - val_acc: 0.9810\n",
      "Epoch 39/50\n",
      "37800/37800 [==============================] - 9s 241us/step - loss: 0.0204 - acc: 0.9940 - val_loss: 0.1039 - val_acc: 0.9805\n",
      "Epoch 40/50\n",
      "37800/37800 [==============================] - 9s 248us/step - loss: 0.0202 - acc: 0.9942 - val_loss: 0.1096 - val_acc: 0.9800\n",
      "Epoch 41/50\n",
      "37800/37800 [==============================] - 12s 310us/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.1069 - val_acc: 0.9802\n",
      "Epoch 42/50\n",
      "37800/37800 [==============================] - 12s 308us/step - loss: 0.0211 - acc: 0.9938 - val_loss: 0.1083 - val_acc: 0.9817\n",
      "Epoch 43/50\n",
      "37800/37800 [==============================] - 15s 388us/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.1247 - val_acc: 0.9790\n",
      "Epoch 44/50\n",
      "37800/37800 [==============================] - 15s 389us/step - loss: 0.0196 - acc: 0.9945 - val_loss: 0.1239 - val_acc: 0.9800\n",
      "Epoch 45/50\n",
      "37800/37800 [==============================] - 17s 463us/step - loss: 0.0211 - acc: 0.9938 - val_loss: 0.1215 - val_acc: 0.9795\n",
      "Epoch 46/50\n",
      "37800/37800 [==============================] - 20s 525us/step - loss: 0.0159 - acc: 0.9955 - val_loss: 0.1290 - val_acc: 0.9790\n",
      "Epoch 47/50\n",
      "37800/37800 [==============================] - 17s 446us/step - loss: 0.0213 - acc: 0.9936 - val_loss: 0.1184 - val_acc: 0.9800\n",
      "Epoch 48/50\n",
      "37800/37800 [==============================] - 13s 344us/step - loss: 0.0209 - acc: 0.9943 - val_loss: 0.1412 - val_acc: 0.9776\n",
      "Epoch 49/50\n",
      "37800/37800 [==============================] - 20s 541us/step - loss: 0.0167 - acc: 0.9951 - val_loss: 0.1267 - val_acc: 0.9776\n",
      "Epoch 50/50\n",
      "37800/37800 [==============================] - 21s 556us/step - loss: 0.0206 - acc: 0.9946 - val_loss: 0.1174 - val_acc: 0.9802\n"
     ]
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain,\n",
    "          validation_data=(Xval, yval), epochs=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(test)\n",
    "numbers=np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids=np.arange(1,numbers.shape[0]+1)\n",
    "df = pd.DataFrame({'ImageId':ids, 'Label': numbers})\n",
    "\n",
    "df.to_csv(\"output/model3.0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### details about this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 199,210\n",
      "Trainable params: 199,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 156.00 556.00\" width=\"156pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-552 152,-552 152,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140151220078688 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140151220078688</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-511.5 11.5,-547.5 136.5,-547.5 136.5,-511.5 11.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74\" y=\"-525.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140151220078800 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140151220078800</title>\n",
       "<polygon fill=\"none\" points=\"23,-438.5 23,-474.5 125,-474.5 125,-438.5 23,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74\" y=\"-452.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140151220078688&#45;&gt;140151220078800 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140151220078688-&gt;140151220078800</title>\n",
       "<path d=\"M74,-511.313C74,-503.289 74,-493.547 74,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.5001,-484.529 74,-474.529 70.5001,-484.529 77.5001,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140151232347888 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140151232347888</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 148,-401.5 148,-365.5 0,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74\" y=\"-379.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 140151220078800&#45;&gt;140151232347888 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140151220078800-&gt;140151232347888</title>\n",
       "<path d=\"M74,-438.313C74,-430.289 74,-420.547 74,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.5001,-411.529 74,-401.529 70.5001,-411.529 77.5001,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140151232347104 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140151232347104</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-292.5 11.5,-328.5 136.5,-328.5 136.5,-292.5 11.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74\" y=\"-306.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140151232347888&#45;&gt;140151232347104 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140151232347888-&gt;140151232347104</title>\n",
       "<path d=\"M74,-365.313C74,-357.289 74,-347.547 74,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.5001,-338.529 74,-328.529 70.5001,-338.529 77.5001,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140151232348056 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140151232348056</title>\n",
       "<polygon fill=\"none\" points=\"23,-219.5 23,-255.5 125,-255.5 125,-219.5 23,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74\" y=\"-233.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140151232347104&#45;&gt;140151232348056 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140151232347104-&gt;140151232348056</title>\n",
       "<path d=\"M74,-292.313C74,-284.289 74,-274.547 74,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.5001,-265.529 74,-255.529 70.5001,-265.529 77.5001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140151232347048 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140151232347048</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 148,-182.5 148,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74\" y=\"-160.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 140151232348056&#45;&gt;140151232347048 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140151232348056-&gt;140151232347048</title>\n",
       "<path d=\"M74,-219.313C74,-211.289 74,-201.547 74,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.5001,-192.529 74,-182.529 70.5001,-192.529 77.5001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140151220080368 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140151220080368</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-73.5 11.5,-109.5 136.5,-109.5 136.5,-73.5 11.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74\" y=\"-87.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 140151232347048&#45;&gt;140151220080368 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140151232347048-&gt;140151220080368</title>\n",
       "<path d=\"M74,-146.313C74,-138.289 74,-128.547 74,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.5001,-119.529 74,-109.529 70.5001,-119.529 77.5001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140151232077608 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140151232077608</title>\n",
       "<polygon fill=\"none\" points=\"23,-0.5 23,-36.5 125,-36.5 125,-0.5 23,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74\" y=\"-14.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 140151220080368&#45;&gt;140151232077608 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140151220080368-&gt;140151232077608</title>\n",
       "<path d=\"M74,-73.3129C74,-65.2895 74,-55.5475 74,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.5001,-46.5288 74,-36.5288 70.5001,-46.5289 77.5001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "plot_model(model, to_file='output/model3.0.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save trained weights\n",
    "model.save(\"model3.0.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
